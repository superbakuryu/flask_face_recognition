

from flask import Flask, render_template, Response
import cv2
import face_recognition
import numpy as np
import os
basedir = os.getcwd()
app = Flask(__name__)
camera = cv2.VideoCapture(0)

# Load my sample picture and learn how to recognize it.
thuan = [-0.08074554055929184, 0.07139841467142105, 0.014842287637293339, -0.10601582378149033, -0.09367229789495468, -0.019333865493535995, -0.11215446889400482, -0.13730312883853912, 0.08377226442098618, -0.13352219760417938, 0.2242102026939392, -0.027582257986068726, -0.1882663518190384, -0.07667768001556396, -0.06747519969940186, 0.17688164114952087, -0.2330702692270279, -0.1440460979938507, -0.031103024259209633, -0.010306226089596748, 0.08890724182128906, -0.0015070741064846516, -0.03590049222111702, 0.03792768344283104, -0.08471047878265381, -0.2969416379928589, -0.0673808678984642, -0.033075928688049316, -0.025786172598600388, 0.03371039777994156, -0.01269455160945654, -0.02096426486968994, -0.21123437583446503, -0.014186443760991096, 0.059547677636146545, 0.06321315467357635, -0.007258403114974499, -0.04112831503152847, 0.16128167510032654, -0.010605398565530777, -0.19725438952445984, 0.0517532080411911, 0.06628188490867615, 0.20401957631111145, 0.1456388384103775, 0.09253624081611633, -0.0045222025364637375, -0.13233217597007751, 0.13449439406394958, -0.22846190631389618, 0.04902604967355728, 0.15019789338111877, 0.05587580427527428, 0.03013010509312153, -0.002794298343360424, -0.15108636021614075, 0.01600753515958786, 0.14611783623695374, -0.10297965258359909, 0.028130944818258286, 0.07400424033403397, -0.0631679892539978, -0.05614389851689339, -
         0.14591924846172333, 0.2616063058376312, 0.1092522069811821, -0.1648245006799698, -0.19359257817268372, 0.13771633803844452, -0.09158045798540115, -0.14120864868164062, 0.0040709213353693485, -0.12105801701545715, -0.16087745130062103, -0.2904043197631836, 0.02814921736717224, 0.3594961166381836, 0.12087486684322357, -0.21262958645820618, 0.0282950010150671, -0.03903522714972496, 0.04945182800292969, 0.14096879959106445, 0.10657337307929993, -0.00655585341155529, 0.007259909063577652, -0.06406930088996887, -0.025720009580254555, 0.23634685575962067, -0.04451211169362068, -0.03782591596245766, 0.2407630831003189, -0.022605331614613533, 0.10448195040225983, -0.00042546307668089867, 0.013270076364278793, -0.04565919563174248, 0.050562940537929535, -0.16063979268074036, 0.017285510897636414, 0.07223638147115707, 0.011462250724434853, 0.016452154144644737, 0.14705127477645874, -0.13242468237876892, 0.10626886039972305, -0.03616985306143761, 0.05379229411482811, 0.041766900569200516, 0.026219049468636513, -0.1277749240398407, -0.06259381771087646, 0.10840032994747162, -0.2112869769334793, 0.2576487958431244, 0.17396147549152374, 0.11182031035423279, 0.09471860527992249, 0.1757553219795227, 0.043634142726659775, 0.02057996392250061, -0.017555806785821915, -0.26634982228279114, -0.06841994822025299, 0.10265325754880905, -0.05354122817516327, 0.08010441064834595, 0.020281175151467323]
thuan_face_encoding = np.array(thuan)

chau_tinh_tri = [-0.03530386835336685, 0.0779341533780098, 0.03827270492911339, -0.051608506590127945, -0.04310286417603493, -0.05071303993463516, -0.047019630670547485, -0.10326702892780304, 0.15020854771137238, -0.16364683210849762, 0.21595342457294464, -0.06831781566143036, -0.2805100381374359, -0.0974673479795456, -0.04077940061688423, 0.16046619415283203, -0.15560640394687653, -0.1764112114906311, -0.06740832328796387, 0.034865602850914, 0.12604843080043793, -0.008684066124260426, -0.03073054552078247, 0.008680915459990501, -0.10918707400560379, -0.30751660466194153, -0.10861454904079437, -0.022910479456186295, -0.008729077875614166, -0.05112762004137039, -0.06807553768157959, 0.018687063828110695, -0.16207154095172882, -0.06593789160251617, 0.03479034826159477, 0.08712627738714218, 0.02525050938129425, -0.05422201380133629, 0.19974178075790405, 0.008367967791855335, -0.28291255235671997, 0.07663718611001968, 0.07437872141599655, 0.22135227918624878, 0.15670481324195862, 0.06760672479867935, -0.018300926312804222, -0.1680850237607956, 0.17437924444675446, -0.1560743749141693, 0.07945539802312851, 0.16020016372203827, 0.15086629986763, 0.09647350758314133, 0.06222137063741684, -0.16679157316684723, 0.08108358830213547, 0.12312686443328857, -0.12465696036815643, -0.02527267299592495, 0.10150968283414841, -0.06000363826751709, 0.06271028518676758, -0.04353226721286774,
                 0.20819590985774994, 0.008886316791176796, -0.09762760251760483, -0.19648349285125732, 0.11005410552024841, -0.1445927768945694, -0.11611119657754898, 0.08846932649612427, -0.1382034420967102, -0.09981124848127365, -0.3446663022041321, 0.0035042744129896164, 0.3762618601322174, 0.10461682826280594, -0.2196916937828064, 0.06462269276380539, -0.0612817220389843, -0.01184971071779728, 0.16405735909938812, 0.10564503818750381, -0.0421491414308548, 0.033136505633592606, -0.14616844058036804, -0.07244863361120224, 0.2709196209907532, -0.021969962865114212, -0.05764097720384598, 0.1759060174226761, 0.037643931806087494, 0.0970597118139267, 0.06850289553403854, -0.011342814192175865, -0.10617148876190186, -0.006247996352612972, -0.15138356387615204, -0.041046760976314545, 0.02138306386768818, -0.04376159608364105, -0.05661319941282272, 0.13496649265289307, -0.17076373100280762, 0.11898604035377502, 0.001394269522279501, 0.03467296063899994, -0.003728381358087063, 0.0554942712187767, -0.10875425487756729, -0.04928601533174515, 0.08061453700065613, -0.24441911280155182, 0.19379109144210815, 0.12788164615631104, 0.09163565188646317, 0.057252805680036545, 0.15380531549453735, 0.07907920330762863, -0.05190500617027283, -0.0016771573573350906, -0.2020532637834549, -0.08246438205242157, 0.11596212536096573, 0.0024987957440316677, 0.16552826762199402, 0.014640403911471367]
chau_tinh_tri_face_encoding = np.array(chau_tinh_tri)

# Create arrays of known face encodings and their names
known_face_encodings = [
    thuan_face_encoding,
    chau_tinh_tri_face_encoding
]
known_face_names = [
    "ThuanMT",
    "Chau Tinh Tri"
]
# Initialize some variables
face_locations = []
face_encodings = []
face_names = []
process_this_frame = True


def gen_frames():
    while True:
        success, frame = camera.read()  # read the camera frame
        if not success:
            break
        else:
            # Resize frame of video to 1/4 size for faster face recognition processing
            small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)
            # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)
            rgb_small_frame = small_frame[:, :, ::-1]

            # Only process every other frame of video to save time

            # Find all the faces and face encodings in the current frame of video
            face_locations = face_recognition.face_locations(rgb_small_frame)
            face_encodings = face_recognition.face_encodings(
                rgb_small_frame, face_locations)
            face_names = []
            for face_encoding in face_encodings:
                # See if the face is a match for the known face(s)
                matches = face_recognition.compare_faces(
                    known_face_encodings, face_encoding)
                name = "Unknown"
                # Or instead, use the known face with the smallest distance to the new face
                face_distances = face_recognition.face_distance(
                    known_face_encodings, face_encoding)
                best_match_index = np.argmin(face_distances)
                if matches[best_match_index]:
                    name = known_face_names[best_match_index]

                face_names.append(name)

            # Display the results
            for (top, right, bottom, left), name in zip(face_locations, face_names):
                # Scale back up face locations since the frame we detected in was scaled to 1/4 size
                top *= 4
                right *= 4
                bottom *= 4
                left *= 4

                # Draw a box around the face
                cv2.rectangle(frame, (left, top),
                              (right, bottom), (0, 0, 255), 2)

                # Draw a label with a name below the face
                cv2.rectangle(frame, (left, bottom - 35),
                              (right, bottom), (0, 0, 255), cv2.FILLED)
                font = cv2.FONT_HERSHEY_DUPLEX
                cv2.putText(frame, name, (left + 6, bottom - 6),
                            font, 1.0, (255, 255, 255), 1)

            ret, buffer = cv2.imencode('.jpg', frame)
            frame = buffer.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')


@app.route('/')
def index():
    return render_template('index.html')


@app.route('/video_feed')
def video_feed():
    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')


if __name__ == '__main__':
    app.run(host='0.0.0.0', debug=True, port=5666)
